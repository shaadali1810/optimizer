{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db1efffd-4f6a-4003-9a94-0a971ebd4d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "#An optimizer is a function or an algorithm that adjusts the attributes of the neural network, such as weights and learning rates. Thus, it helps in reducing the overall loss and improving accuracy.\n",
    "#Optimization algorithms:Optimization algorithms are a class of algorithms that are used to find the best possible solution to a given problem. The goal of an optimization algorithm is to find the optimal solution that minimizes or maximizes a given objective function.\n",
    "#Optimizers are algorithms or methods used to change the attributes of your neural network such as weights and learning rate in order to reduce the losses. How you should change your weights or learning rates of your neural network to reduce the losses is defined by the optimizers you use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e01004b0-c9ba-4fbe-a879-19fb8e00231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent in machine learning is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.\n",
    "#A space–time trade off can be applied to the problem of data storage. If data is stored uncompressed, it takes more space but access takes less time than if the data were stored compressed (since compressing the data reduces the amount of space it takes, but it takes time to run the decompression algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95786316-f3b8-414e-9c90-6c48df29bb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3If the execution is not done properly while using gradient descent, it may lead to problems like vanishing gradient or exploding gradient problems. These problems occur when the gradient is too small or too large. And because of this problem the algorithms do not converge.8 Mar 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ef7d102-5a05-4637-8879-4093b362d7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#he main disadvantage of gradient-based methods is that they are sensitive to the choice of the initial point, the step size, and the noise in the function. They can also get stuck in local optima or saddle points and fail to explore the global optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "023910bf-5c4f-436a-961f-5789f3568e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Many difficulties are associated with the optimization of large-scale problems. The major difficulties are multi-modality, dimensionality and differentiability. Traditional techniques generally fail to solve such large-scale problems especially with nonlinear objective function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffa041be-88e0-48f1-bdd7-d22cd6beac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Momentum can accelerate training and learning rate schedules can help to converge the optimization process. Adaptive learning rates can accelerate training and alleviate some of the pressure of choosing a learning rate and learning rate schedule.\n",
    "#Momentum is an extension to the gradient descent optimization algorithm that builds inertia in a search direction to overcome local minima and oscillation of noisy gradients. It is based on the same concept of momentum i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "961adeb8-a534-4c4c-a025-11e956e465ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"compared with BGD's calculation of gradients with all data at one time, SGD updates the gradient of each sample with each update.\\n\\n`x += - learning_rate * dx`\\n\\nwhere x is a parameter, dx is the gradient and learning rate is constant\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5\n",
    "'''compared with BGD's calculation of gradients with all data at one time, SGD updates the gradient of each sample with each update.\n",
    "\n",
    "`x += - learning_rate * dx`\n",
    "\n",
    "where x is a parameter, dx is the gradient and learning rate is constant'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e033cb3-992c-4fe1-b30c-e6f0468c8e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6It calculates a moving average of the first-order moments (the mean of gradients) and the second-order moments (the uncentered variance of gradients) to scale the learning rates adaptively. This makes it well-suited for problems with sparse gradients or noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f8bbe6f-85eb-46d2-a3d3-fc0b8c5ea8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7RMSprop is an innovative stochastic mini-batch learning method. RMSprop (Root Mean Squared Propagation) is an optimization algorithm used in deep learning and other Machine Learning techniques.\n",
    "#Similar to RMSProp, Adam optimizer considers the second moment of the gradients, but unlike RMSProp, it calculates the uncentered variance of the gradients (without subtracting the mean).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f95ae2e8-0300-4323-a0c3-ed567ed46a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d635c893-4125-46ce-bcd8-8eeea232dad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.1)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.11)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.63.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc4599b9-d366-4b32-bc01-65bbba1085d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 11:44:50.186056: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-02 11:44:50.190866: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-02 11:44:50.265548: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-02 11:44:51.576696: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d19594d1-8ced-41e8-8420-e6a782be164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6eb61c7-b7ed-4ec6-bb04-50c6e78b955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full,Y_train_full),(X_test,Y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff512e22-d3a1-4d79-b2a8-68c817ecde3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d97ef49-7163-436c-bb78-f5e58ceb8db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "OPTIMIZER=[SGD,Adam,RMSprop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f0ca060-78fb-4fb5-87da-240e43f8f8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,X_valid)=X_train_full[:50000]/255,X_train_full[50000:]/255\n",
    "(Y_train,Y_valid)=Y_train_full[:50000]/255,X_train_full[50000]/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d307189d-cb4c-4d7e-97e2-c8e39ca03938",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.optimizers.SGD())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "154ad66a-3c3e-496a-8f15-ad69da50a671",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.optimizers.RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ecae727a-4765-49fd-b86b-ce9cdebbad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b611ce27-6b54-4829-8b5b-fe9c3b506cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10,\n",
    "VALIDATION_SET=(X_valid,Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7cab58f8-3970-4a43-9fd9-44797df8069c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5786e-04\n"
     ]
    }
   ],
   "source": [
    "HISTORY=model.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376b57d0-ed31-449b-8bc7-5863bd99dcf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
